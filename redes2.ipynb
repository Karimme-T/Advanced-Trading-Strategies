{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9478e1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85380d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ejecutar_notebook_y_extraer_vars(nb_path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    Ejecuta secuencialmente las celdas de código del notebook dado y devuelve\n",
    "    un diccionario con las variables definidas (namespace).\n",
    "\n",
    "    No modifica el .ipynb original.\n",
    "    \"\"\"\n",
    "    import nbformat, runpy\n",
    "\n",
    "    nb = nbformat.read(str(nb_path), as_version=4)\n",
    "    # Ambiente aislado donde se ejecutarán las celdas\n",
    "    ns = {}\n",
    "    # Ejecutar solo celdas de código en orden\n",
    "    for cell in nb.cells:\n",
    "        if cell.cell_type == \"code\":\n",
    "            code = cell.source\n",
    "            if code.strip():\n",
    "                exec(compile(code, filename=\"<notebook_cell>\", mode=\"exec\"), ns, ns)\n",
    "    return ns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac1afd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_Xy_desde_namespace(ns: dict):\n",
    "    \"\"\"\n",
    "    Intenta recuperar los DataFrames preprocesados del notebook:\n",
    "      - train_scaled (features estandarizadas por día, con columna 'date' y quizás 'Close', etc.)\n",
    "      - train_df     (debe contener columna 'signal' con {-1,0,1})\n",
    "    Construye X (features) e y (etiquetas) alineados por índice temporal.\n",
    "    \"\"\"\n",
    "    if \"train_scaled\" not in ns:\n",
    "        raise RuntimeError(\"No se encontró 'train_scaled' en el notebook. Asegúrate de ejecutar feature_eng.ipynb antes.\")\n",
    "    if \"train_df\" not in ns:\n",
    "        raise RuntimeError(\"No se encontró 'train_df' en el notebook. Asegúrate de ejecutar feature_eng.ipynb antes.\")\n",
    "\n",
    "    train_scaled = ns[\"train_scaled\"].copy()\n",
    "    train_df = ns[\"train_df\"].copy()\n",
    "\n",
    "    # Alinear por índice (suponemos orden temporal ya preservado en el notebook)\n",
    "    df_merged = train_scaled.join(train_df[[\"signal\"]], how=\"inner\")\n",
    "    # Features = todo salvo 'date' y 'signal'\n",
    "    X = df_merged.drop(columns=[c for c in [\"date\", \"signal\"] if c in df_merged.columns], errors=\"ignore\").values.astype(np.float32)\n",
    "    y_signal = df_merged[\"signal\"].astype(int).values  # {-1,0,1}\n",
    "\n",
    "    # Mapear a 0..K-1 para Keras\n",
    "    clases_unicas = sorted(np.unique(y_signal).tolist())\n",
    "    clase2idx = {c: i for i, c in enumerate(clases_unicas)}\n",
    "    idx2clase = {i: c for c, i in clase2idx.items()}\n",
    "    y = np.array([clase2idx[c] for c in y_signal], dtype=np.int64)\n",
    "\n",
    "    return SimpleNamespace(\n",
    "        X=X,\n",
    "        y=y,\n",
    "        clases_unicas=clases_unicas,\n",
    "        clase2idx=clase2idx,\n",
    "        idx2clase=idx2clase,\n",
    "        train_scaled=train_scaled,\n",
    "        train_df=train_df,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107e7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_temporal(X, y, val_ratio=0.15, test_ratio=0.15):\n",
    "    \"\"\"\n",
    "    Split temporal: primeros registros -> train, luego val y test.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    n_test = int(n * test_ratio)\n",
    "    n_val = int(n * val_ratio)\n",
    "    n_train = n - n_val - n_test\n",
    "    return (X[:n_train], y[:n_train],\n",
    "            X[n_train:n_train+n_val], y[n_train:n_train+n_val],\n",
    "            X[n_train+n_val:], y[n_train+n_val:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb1c9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_class_weights(y_train):\n",
    "    clases = np.unique(y_train)\n",
    "    pesos = compute_class_weight(class_weight=\"balanced\", classes=clases, y=y_train)\n",
    "    return {int(c): float(w) for c, w in zip(clases, pesos)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a64f5d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_mlp(n_features, n_clases, hidden=(128, 64), dropout=0.2, lr=1e-3):\n",
    "    inputs = keras.Input(shape=(n_features,))\n",
    "    x = inputs\n",
    "    for h in hidden:\n",
    "        x = layers.Dense(h, activation=\"relu\")(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    outputs = layers.Dense(n_clases, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"MLP_Baseline\")\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8c6dae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_ventanas(X, y, window=32, horizon=1, step=1):\n",
    "    \"\"\"\n",
    "    Convierte series diarias X (N, F) en secuencias para CNN: (M, window, F)\n",
    "    La etiqueta es la del tiempo t + horizon en el extremo de la ventana.\n",
    "    \"\"\"\n",
    "    N = len(X)\n",
    "    fin = N - window - horizon + 1\n",
    "    if fin <= 0:\n",
    "        raise ValueError(\"Datos insuficientes para la ventana/horizonte.\")\n",
    "    X_seq, y_seq = [], []\n",
    "    for i in range(0, fin, step):\n",
    "        X_seq.append(X[i:i+window])\n",
    "        y_seq.append(y[i+window-1 + horizon])\n",
    "    return np.asarray(X_seq, dtype=np.float32), np.asarray(y_seq, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b29024c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construir_cnn_1d(window, n_features, n_clases,\n",
    "                     filtros=(64, 128), kernel_size=3, pool_size=2, dropout=0.3, lr=1e-3):\n",
    "    inputs = keras.Input(shape=(window, n_features))\n",
    "    x = inputs\n",
    "    for f in filtros:\n",
    "        x = layers.Conv1D(filters=f, kernel_size=kernel_size, padding=\"causal\", activation=\"relu\")(x)\n",
    "        x = layers.MaxPooling1D(pool_size=pool_size)(x)\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    outputs = layers.Dense(n_clases, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs, outputs, name=\"CNN1D_Temporal\")\n",
    "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                  loss=\"sparse_categorical_crossentropy\",\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c993919",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar(model, X_test, y_test, idx2clase):\n",
    "    proba = model.predict(X_test, verbose=0)\n",
    "    y_pred = np.argmax(proba, axis=1)\n",
    "    target_names = [str(idx2clase[i]) for i in sorted(idx2clase.keys())]\n",
    "    print(\"\\nMatriz de confusión:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"\\nReporte de clasificación:\\n\", classification_report(y_test, y_pred, target_names=target_names, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7799af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_mlp(ns_data, epochs=200, batch_size=256):\n",
    "    X, y = ns_data.X, ns_data.y\n",
    "    Xtr, ytr, Xva, yva, Xte, yte = split_temporal(X, y, val_ratio=0.15, test_ratio=0.15)\n",
    "    cw = preparar_class_weights(ytr)\n",
    "    model = construir_mlp(n_features=X.shape[1], n_clases=len(np.unique(y)))\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-5),\n",
    "    ]\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=epochs, batch_size=batch_size, class_weight=cw, callbacks=callbacks, verbose=1)\n",
    "    evaluar(model, Xte, yte, ns_data.idx2clase)\n",
    "    model.save(\"mlp_baseline.keras\")\n",
    "    print(\"✔ Guardado: mlp_baseline.keras\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a837883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrenar_cnn(ns_data, window=32, horizon=1, epochs=200, batch_size=256):\n",
    "    X, y = ns_data.X, ns_data.y\n",
    "    # Ventanas sobre TODO el histórico en escala ya estandarizada\n",
    "    X_seq, y_seq = construir_ventanas(X, y, window=window, horizon=horizon, step=1)\n",
    "    n = len(X_seq)\n",
    "    n_test = int(n * 0.15)\n",
    "    n_val = int(n * 0.15)\n",
    "    n_train = n - n_val - n_test\n",
    "    Xtr, ytr = X_seq[:n_train], y_seq[:n_train]\n",
    "    Xva, yva = X_seq[n_train:n_train+n_val], y_seq[n_train:n_train+n_val]\n",
    "    Xte, yte = X_seq[n_train+n_val:], y_seq[n_train+n_val:]\n",
    "\n",
    "    cw = preparar_class_weights(ytr)\n",
    "    model = construir_cnn_1d(window=window, n_features=X.shape[1], n_clases=len(np.unique(y)))\n",
    "    callbacks = [\n",
    "        keras.callbacks.EarlyStopping(patience=12, restore_best_weights=True, monitor=\"val_loss\"),\n",
    "        keras.callbacks.ReduceLROnPlateau(patience=6, factor=0.5, min_lr=1e-5),\n",
    "    ]\n",
    "    model.fit(Xtr, ytr, validation_data=(Xva, yva),\n",
    "              epochs=epochs, batch_size=batch_size, class_weight=cw, callbacks=callbacks, verbose=1)\n",
    "    evaluar(model, Xte, yte, ns_data.idx2clase)\n",
    "    model.save(\"cnn_temporal.keras\")\n",
    "    print(\"✔ Guardado: cnn_temporal.keras\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac91a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"Continuación DL: MLP y CNN a partir de feature_eng.ipynb (sin modificarlo)\")\n",
    "    parser.add_argument(\"--nb\", required=True, help=\"Ruta al feature_eng.ipynb\")\n",
    "    parser.add_argument(\"--modelo\", choices=[\"mlp\", \"cnn\"], required=True, help=\"Modelo a entrenar\")\n",
    "    parser.add_argument(\"--window\", type=int, default=32, help=\"(CNN) Tamaño de ventana\")\n",
    "    parser.add_argument(\"--horizon\", type=int, default=1, help=\"(CNN) Horizonte de predicción\")\n",
    "    parser.add_argument(\"--epochs\", type=int, default=200, help=\"Épocas de entrenamiento\")\n",
    "    parser.add_argument(\"--batch-size\", type=int, default=256, help=\"Tamaño de lote\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    nb_path = Path(args.nb)\n",
    "    if not nb_path.exists():\n",
    "        print(f\"[ERROR] No se encontró el notebook en: {nb_path}\", file=sys.stderr)\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(f\"Ejecutando notebook para importar resultados → {nb_path}\")\n",
    "    ns = ejecutar_notebook_y_extraer_vars(nb_path)\n",
    "    print(\"✔ Notebook ejecutado. Extrayendo matrices X,y…\")\n",
    "    ns_data = extraer_Xy_desde_namespace(ns)\n",
    "\n",
    "    if args.modelo == \"mlp\":\n",
    "        entrenar_mlp(ns_data, epochs=args.epochs, batch_size=args.batch_size)\n",
    "    else:\n",
    "        entrenar_cnn(ns_data, window=args.window, horizon=args.horizon,\n",
    "                     epochs=args.epochs, batch_size=args.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a66f47f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "NB_PATH = Path(\"feature_eng.ipynb\")\n",
    "WINDOW = 32\n",
    "HORIZON = 1\n",
    "EPOCHS = 200\n",
    "BATCH_SIZE = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f7b5cff9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nbformat'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ns = \u001b[43mejecutar_notebook_y_extraer_vars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNB_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m data = extraer_Xy_desde_namespace(ns)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mListo: X,y extraídos. Clases:\u001b[39m\u001b[33m\"\u001b[39m, data.clases_unicas)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mejecutar_notebook_y_extraer_vars\u001b[39m\u001b[34m(nb_path)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mejecutar_notebook_y_extraer_vars\u001b[39m(nb_path: Path) -> \u001b[38;5;28mdict\u001b[39m:\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m    Ejecuta secuencialmente las celdas de código del notebook dado y devuelve\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    un diccionario con las variables definidas (namespace).\u001b[39;00m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[33;03m    No modifica el .ipynb original.\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnbformat\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01mrunpy\u001b[39;00m\n\u001b[32m     10\u001b[39m     nb = nbformat.read(\u001b[38;5;28mstr\u001b[39m(nb_path), as_version=\u001b[32m4\u001b[39m)\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Ambiente aislado donde se ejecutarán las celdas\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nbformat'"
     ]
    }
   ],
   "source": [
    "ns = ejecutar_notebook_y_extraer_vars(NB_PATH)\n",
    "data = extraer_Xy_desde_namespace(ns)\n",
    "print(\"Listo: X,y extraídos. Clases:\", data.clases_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0fbdb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = entrenar_mlp(data, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc6c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = entrenar_cnn(data, window=WINDOW, horizon=HORIZON, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1aabe9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.8.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
